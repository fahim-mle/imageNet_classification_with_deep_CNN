# ğŸ¤– ImageNet Classification with Deep CNN

> ğŸš€ **Building and comparing deep convolutional neural network models for image classification across multiple modern ML frameworks**

---

## ğŸ“‹ Project Overview

This project focuses on building and comparing deep convolutional neural network (CNN) models for image classification using multiple modern machine-learning frameworks. Inspired by the foundational AlexNet architecture, the goal is to design, train, and evaluate custom CNNs while also leveraging state-of-the-art pretrained models.

### ğŸ¯ Objectives

- ğŸ”§ Design custom CNN architectures based on AlexNet
- ğŸ—ï¸ Implement models across three major frameworks
- ğŸ“Š Compare performance and workflows
- ğŸ”¬ Analyze architectural impacts on results
- ğŸ“ˆ Establish reproducible experimentation foundation

### ğŸ› ï¸ Technology Stack

The project includes **three parallel implementations**:

| Framework | Type | Purpose |
|-----------|------|---------|
| ğŸ”¥ **PyTorch** | Custom baseline | Deep learning research framework |
| ğŸ§  **TensorFlow/Keras** | Custom baseline | Production-ready framework |
| ğŸ¤— **Hugging Face** | Transfer learning | State-of-the-art pretrained models |

All models will be trained and tested on a chosen Kaggle image dataset, using consistent preprocessing, evaluation metrics, and output logging. The final objective is to analyze performance differences, understand architectural impacts, and produce a clear comparison of deep-learning workflows across different frameworks.

This repo serves as a clean, maintainable foundation for experimentation, reproducibility, and extension into broader computer-vision research or MLOps practices.

---

## ğŸ—ï¸ Building and Running

### 1ï¸âƒ£ Project Build Rules

ğŸ“ **Code Organization**
- âœ… Keep all code inside `src/`, organized by purpose (`common/`, `experiments/`, etc.)
- ğŸ“¦ Add new dependencies only in `requirements.txt`
- ğŸš« Never hard-code local paths
- âš™ï¸ Use config files (YAML/JSON under `configs/`) for hyperparameters, dataset paths, model settings

ğŸ”§ **Code Generation Guidelines**
- ğŸ“ Follow PEP8 formatting
- ğŸ“¦ Keep files small and modular
- ğŸ”§ Put reusable utilities into `src/common/`
- ğŸš« Never store datasets or checkpoints in Git (only `.gitkeep` files)

### 2ï¸âƒ£ How to Run the Project

For every model (PyTorch, TF, HF) the agent must:

ğŸ“‹ **Setup Steps**
1. âš™ï¸ Load configs from `configs/`
2. ğŸ“‚ Load dataset from `data/processed/` (document expected folder structure)
3. ğŸƒ Run training using scripts under `scripts/`:
   - `scripts/train_pytorch.py`
   - `scripts/train_tensorflow.py`
   - `scripts/train_hf.py`

ğŸ“Š **Output Management**
Save all outputs into the correct subfolders:
- ğŸ“Š **logs** â†’ `outputs/logs/`
- ğŸ“ˆ **metrics** â†’ `outputs/metrics/`
- ğŸ”® **predictions** â†’ `outputs/predictions/`
- ğŸ’¾ **model weights** â†’ `models/`

ğŸ”„ **Runtime Requirements**
- ğŸ“ˆ Always log: loss curves, accuracy curves, confusion matrix (if classification)
- ğŸ’¾ Always save: final model, config used, training summary file (JSON)

### 3ï¸âƒ£ How to Test the Project

The agent must implement **three layers of testing**:

#### ğŸ§ª A. Sanity Tests (required for every training script)
- âœ… Check dataset loads without errors
- âœ… Check model instantiates correctly
- âœ… Run a single forward pass on 1â€“2 samples
- âœ… Verify training loop for 1 batch works

#### ğŸ”§ B. Functional Tests (placed in `src/tests/`)
- ğŸ”„ Test preprocessing pipeline
- ğŸ’¾ Test model saves/loads correctly
- ğŸ“Š Test metrics computation (accuracy, loss)

#### ğŸ“ˆ C. Evaluation Tests
After training, always produce:
- ğŸ“Š Accuracy on train/test split
- ğŸ“ˆ Loss curves
- ğŸ“„ Metrics JSON file
- ğŸ–¼ï¸ 5â€“10 example predictions saved as images or text

### 4ï¸âƒ£ Execution Workflow for the Agent

Whenever the agent adds or modifies code, it must follow this sequence:

1. ğŸ“¦ Update dependencies if needed â†’ `requirements.txt`
2. ğŸ“ Generate code inside the correct folder
3. ğŸ§ª Run sanity tests
4. ğŸ“– Document usage in README or a small HOW-TO comment at top of script
5. ğŸ’¾ Commit changes with a meaningful message

### 5ï¸âƒ£ Branching Workflow

ğŸŒ³ **Branch Strategy**
- ğŸŒŸ **Main branch** â†’ stable scaffold and docs
- ğŸš€ **New model** â†’ create feature branch (`feature/pytorch_baseline`, etc.)

ğŸ”„ **Merge Process**
After finishing:
- âœ… Ensure code runs end-to-end with sanity tests
- ğŸ”„ Merge back into main

### 6ï¸âƒ£ Efficiency & Optimization Rules

âš¡ **Performance Guidelines**
- ğŸ¯ Prefer small batches and lower-res images for development (due to 4 GB VRAM)
- ğŸ² Use deterministic seeding
- ğŸ”„ Use shared data loader utilities for all frameworks
- ğŸ’¾ Cache preprocessed data in `data/processed/`

---

## ğŸ‘¨â€ğŸ’» Development Conventions

### ğŸ“ Coding Standards
- ğŸ Follow PEP8 formatting for Python code
- ğŸ“ Use clear, descriptive variable names
- ğŸ“¦ Keep functions small and focused
- ğŸ“– Add docstrings to all public functions and classes

### ğŸ§ª Testing Practices
- âœ… Write tests for all new functionality
- ğŸ”„ Run tests before committing changes
- ğŸ“Š Maintain test coverage above 80%
- ğŸ§ª Include both unit and integration tests

### ğŸ“š Documentation
- ğŸ“– Keep README files up to date
- ğŸ’¬ Comment complex logic
- ğŸ“Š Document API changes
- ğŸ”„ Update configuration examples

---

## ğŸš€ Getting Started

### ğŸ“‹ Prerequisites
- Python 3.8+
- CUDA-compatible GPU (recommended)
- Git

### âš™ï¸ Installation
```bash
# Clone the repository
git clone <repository-url>
cd imageNet_classification_with_deep_CNN

# Install dependencies
pip install -r requirements.txt

# Setup directories
mkdir -p data/{raw,processed} outputs/{logs,metrics,predictions} models configs
```

### ğŸƒ Quick Start
```bash
# Train PyTorch model
python scripts/train_pytorch.py --config configs/pytorch_config.yaml

# Train TensorFlow model
python scripts/train_tensorflow.py --config configs/tensorflow_config.yaml

# Train Hugging Face model
python scripts/train_hf.py --config configs/hf_config.yaml
```

---

## ğŸ“Š Project Structure

```
imageNet_classification_with_deep_CNN/
â”œâ”€â”€ ğŸ“ src/                    # Source code
â”‚   â”œâ”€â”€ ğŸ“ common/             # Shared utilities
â”‚   â”œâ”€â”€ ğŸ“ experiments/        # Experiment scripts
â”‚   â””â”€â”€ ğŸ“ tests/              # Test files
â”œâ”€â”€ ğŸ“ scripts/               # Training scripts
â”œâ”€â”€ ğŸ“ configs/               # Configuration files
â”œâ”€â”€ ğŸ“ data/                  # Data directories
â”‚   â”œâ”€â”€ ğŸ“ raw/               # Raw datasets
â”‚   â””â”€â”€ ğŸ“ processed/         # Processed datasets
â”œâ”€â”€ ğŸ“ outputs/               # Training outputs
â”‚   â”œâ”€â”€ ğŸ“ logs/              # Training logs
â”‚   â”œâ”€â”€ ğŸ“ metrics/           # Evaluation metrics
â”‚   â””â”€â”€ ğŸ“ predictions/       # Model predictions
â”œâ”€â”€ ğŸ“ models/                # Saved model weights
â”œâ”€â”€ ğŸ“„ requirements.txt       # Python dependencies
â”œâ”€â”€ ğŸ“„ README.md              # Project documentation
â””â”€â”€ ğŸ“„ GEMINI.md              # This file
```
---

*Last updated: November 2025*
